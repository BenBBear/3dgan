{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "from tf_util import *\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "ok()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gan_feature_matching_volume_soft_softmax'\n",
    "log = Log(model_name)\n",
    "model_path = make_model_path(model_name)\n",
    "model_images_path = make_model_images_path(model_name)\n",
    "mkdir(model_images_path)\n",
    "input_shape = (30, 30, 30, 1)\n",
    "n_epoch = 10\n",
    "test_freq = 100\n",
    "save_freq = 500\n",
    "batch_size = 32\n",
    "z_dim_list = [4, 4, 4, 1]\n",
    "z_dim = list_prod(z_dim_list)\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.99\n",
    "test_batch_size = 4\n",
    "use_feature_matching = True\n",
    "conditional = False\n",
    "conditional_dim = 12\n",
    "angle=[6,]\n",
    "ok()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "if angle == 'all':\n",
    "    angle = [i for i in range(1, 13)]\n",
    "\n",
    "\n",
    "def load_data(label='chair'):\n",
    "    return pickle_load(join(volume_data_path__,\n",
    "                            label + '_30_angle_' +\n",
    "                            \",\".join([str(i) for i in angle])+'.pickle'))\n",
    "\n",
    "\n",
    "def test_fun(model=None, n_iter=0, losses=[]):\n",
    "    plot_loss(losses, title=model_name + \"_loss\",\n",
    "              save_to=join(model_images_path, '{0}_loss.png'.format(n_iter)))\n",
    "    gen_volumes = model.generate_data(batch_size=test_batch_size)\n",
    "    gen_volumes = numpy_array_spiking(gen_volumes)\n",
    "    savemat(join(model_images_path, '{0}_volume'.format(n_iter)), {\n",
    "        'instance': gen_volumes\n",
    "    })\n",
    "    plot_grid_volume(gen_volumes, dim=(1, test_batch_size), volume_shape=input_shape[:-1],\n",
    "                     save_to=join(model_images_path, '{0}_volume_snapshot.png'.format(n_iter)))\n",
    "    \n",
    "ok()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "def g_net(z, reuse=False, label=None):\n",
    "    h = dense(z, 2*2*2*(64*8), name=\"g_dense_1\", reuse=reuse, activation=tf_relu)\n",
    "    h = tf_reshape_for_conv(h, [2, 2, 2, 64*8])\n",
    "    h = tf_batch_norm(h, mode='3d', reuse=reuse, name=\"gbn_0\")\n",
    "    h = tf_deconv3d(h, [4, 4, 4, 64*4], name=\"g_deconv3d_1\",\n",
    "                    activation=tf_relu, reuse=reuse, bn=True)\n",
    "    h = tf_deconv3d(h, [8, 8, 8, 64*2], name=\"g_deconv3d_2\",  activation=tf_relu,                             reuse=reuse, bn=True)\n",
    "    h = tf_deconv3d(h, [15, 15, 15, 64], name=\"g_deconv3d_3\", activation=tf_relu,                              reuse=reuse, bn=True)\n",
    "    h = tf_deconv3d(h, [30, 30, 30, 1], name=\"g_deconv3d_4\",\n",
    "                    activation=tf_tanh, reuse=reuse)\n",
    "    return h\n",
    "\n",
    "\n",
    "def d_net(input_var, reuse=False, label=None):\n",
    "    h = tf_conv3d(input_var, 64,  name=\"d_conv_1\",\n",
    "                  activation=tf_leaky_relu(), reuse=reuse)\n",
    "    h = tf_conv3d(h, 64*2,  name=\"d_conv_2\",\n",
    "                  activation=tf_leaky_relu(), reuse=reuse, bn=True)\n",
    "    h = tf_conv3d(h, 64*4,  name=\"d_conv_3\",\n",
    "                  activation=tf_leaky_relu(), reuse=reuse, bn=True)\n",
    "    h = tf_conv3d(h, 64*8,  name=\"d_conv_4\",\n",
    "                  activation=tf_leaky_relu(), reuse=reuse, bn=True)\n",
    "    h = tf_flatten_for_dense(h)\n",
    "    feature_matching_layer = h\n",
    "    h = tf_dense(h, 1, name=\"dense_1\", reuse=reuse)\n",
    "    if use_feature_matching:\n",
    "        return h, tf_sigmoid(h), feature_matching_layer\n",
    "    else:\n",
    "        return h, tf_sigmoid(h)\n",
    "\n",
    "ok()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading Data\n",
      "LOG: Finished!\n",
      "LOG: Building Graph\n",
      "INFO:tensorflow:Summary name D dis--gan_feature_matching_volume_soft_softmax is illegal; using D_dis--gan_feature_matching_volume_soft_softmax instead.\n",
      "INFO:tensorflow:Summary name D gen--gan_feature_matching_volume_soft_softmax is illegal; using D_gen--gan_feature_matching_volume_soft_softmax instead.\n",
      "LOG: Initializing parameters\n",
      "LOG: Finished!\n"
     ]
    }
   ],
   "source": [
    "session = tf.InteractiveSession()\n",
    "log('Loading Data')\n",
    "data = load_data(chair)\n",
    "volume_data = soften_categorical_labels(data['data'].astype(np.float32), l=0.1, h=0.9)\n",
    "volume_label = data['label']\n",
    "log('Finished!')\n",
    "volume_num = volume_data.shape[0]\n",
    "\n",
    "\n",
    "def volume_next_batch(bs):\n",
    "    batch_indexes = get_batch_indexes(volume_num, bs, shuffle=False)\n",
    "    batch_volumes = volume_data[batch_indexes, :]\n",
    "    batch_labels = volume_label[batch_indexes]\n",
    "    return batch_volumes, batch_labels\n",
    "\n",
    "log('Building Graph')\n",
    "gan = GanModel(input_dim=input_shape, z_dim=z_dim,\n",
    "               g_net=g_net,\n",
    "               d_net=d_net,\n",
    "               optimizer=lambda: tf.train.AdamOptimizer(lr, beta1=beta1, beta2=beta2),\n",
    "               name=model_name,\n",
    "               session=session,\n",
    "               save_freq=save_freq,\n",
    "               conditional=conditional,\n",
    "               conditional_dim=conditional_dim,\n",
    "               next_batch=volume_next_batch, reuse=False,\n",
    "               batch_size=batch_size, log=log, test_freq=test_freq, test_fun=test_fun,\n",
    "               feature_matching=use_feature_matching, feature_matching_weight=1.0)\n",
    "log('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "G:   0%|          | 0/309 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Beginning Training\n"
     ]
    }
   ],
   "source": [
    "# Training Block\n",
    "\n",
    "log(\"Beginning Training\")\n",
    "gan.train(steps=[('G', int(volume_num/batch_size*n_epoch), 1.0, 2)],\n",
    "          log=None, save=True, test=True)\n",
    "# ok()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing Block\n",
    "# for i in range(3):\n",
    "#     gan.test(stamp=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
